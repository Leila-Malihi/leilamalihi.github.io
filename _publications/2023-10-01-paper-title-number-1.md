---
title: "Analyzing the Inference
Process in Deep Convolutional Neural Networks using Principal Eigenfeatures,
Saturation and Logistic Regression Probes"
collection: publications
permalink: /publication/2009-10-01-paper-title-number-1
excerpt: 'The predictive performance of a neural network depends on the one hand on the difficulty of a problem, defined
by the number of classes and complexity of the visual domain, and on the other hand on the capacity of the model,
determined by the number of parameters and its structure. By applying layer saturation and logistic regression probes,
we confirm that these factors influence the inference process in an antagonistic manner. This analysis allows the detection
of over- and under-parameterization of convolutional neural networks. We show that the observed effects are
independent of previously reported pathological patterns, like the “tail pattern”. In addition, we study the emergence of
saturation patterns during training, showing that saturation patterns emerge early in the optimization process. This
allows for quick detection of problems and potentially decreased cycle time during experiments. We also demonstrate
that the emergence of tail patterns is independent of the capacity of the networks. Finally, we show that information
processing within a tail of unproductive layers is different, depending on the topology of the neural network architecture.'
date: 2023-12-01
venue: 'Journal of Applied Research in Electrical
Engineering'
paperurl: 'http://academicpages.github.io/files/paper1.pdf'
citation: 'Richter M.L, Malihi. L, Windler, A.K.P., Krumnack. U. (2023). &quot;Analyzing the Inference
Process in Deep Convolutional Neural Networks using Principal Eigenfeatures,
Saturation and Logistic Regression Probes.&quot; <i>Journal of Applied Research in Electrical
Engineering</i>. 1(1).'
---
The predictive performance of a neural network depends on the one hand on the difficulty of a problem, defined
by the number of classes and complexity of the visual domain, and on the other hand on the capacity of the model,
determined by the number of parameters and its structure. By applying layer saturation and logistic regression probes,
we confirm that these factors influence the inference process in an antagonistic manner. This analysis allows the detection
of over- and under-parameterization of convolutional neural networks. We show that the observed effects are
independent of previously reported pathological patterns, like the “tail pattern”. In addition, we study the emergence of
saturation patterns during training, showing that saturation patterns emerge early in the optimization process. This
allows for quick detection of problems and potentially decreased cycle time during experiments. We also demonstrate
that the emergence of tail patterns is independent of the capacity of the networks. Finally, we show that information
processing within a tail of unproductive layers is different, depending on the topology of the neural network architecture.
[Download paper here](http://academicpages.github.io/files/papermat.pdf)

Recommended citation: Richter M.L, Malihi. L, Windler, A.K.P., Krumnack. U. (2023). "Analyzing the Inference
Process in Deep Convolutional Neural Networks using Principal Eigenfeatures,
Saturation and Logistic Regression Probes." <i>Journal of Applied Research in Electrical
Engineering</i>. 1(1).
